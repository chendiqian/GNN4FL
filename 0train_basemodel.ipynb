{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03aa8e6d-6601-4ff7-bcf1-efecb4d6f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a910df39-2442-4d01-8810-6239023b91b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = MNIST('./datasets', train=True, download=True, transform=transform)\n",
    "\n",
    "val_dataset = MNIST('./datasets', train=False, download=True, transform=transform)\n",
    "np.random.seed(2023)\n",
    "valset = torch.utils.data.Subset(val_dataset, np.random.randint(0,\n",
    "                                                         len(val_dataset),\n",
    "                                                         5000))\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c5c0cf-1fdd-4f38-8a8f-30742c62344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_cnn import MNIST_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b639a22-68ab-4c9f-889f-6e592a2f439b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4266d-b363-4570-83bb-87c9733cc71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_CNN().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be128c76-8e42-4695-a2b6-61210b97dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "num_trained_models = 500\n",
    "batchsize = 64\n",
    "num_data_per_model = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591027fb-4f66-4e56-a441-d3509ca03a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a267af-d5c0-4431-ab38-50347dd8fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_val import mnist_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa6154-6657-4f2b-85a4-0f84d24556cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(num_trained_models):\n",
    "    trainset = torch.utils.data.Subset(train_dataset,\n",
    "                                       np.random.randint(0,\n",
    "                                                         len(train_dataset),\n",
    "                                                         num_data_per_model))\n",
    "    dataloader = torch.utils.data.DataLoader(trainset,\n",
    "                                             batch_size=batchsize,\n",
    "                                             shuffle=True)\n",
    "\n",
    "    model.reset_parameters(2023)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    best_val_acc = 0.\n",
    "\n",
    "    pbar = tqdm(range(epochs))\n",
    "    pbar.set_description(f'{m} th model')\n",
    "    for epoch in pbar:  # loop over the dataset multiple times\n",
    "        counts = 0\n",
    "        corrects = 0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to('cuda:0')\n",
    "            labels = labels.to('cuda:0')\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            counts += inputs.shape[0]\n",
    "            corrects += (outputs.argmax(1) == labels).sum()\n",
    "            \n",
    "#         model.eval()\n",
    "#         acc = mnist_validation(val_loader, model)\n",
    "        \n",
    "#         if acc > best_val_acc:\n",
    "#             best_val_acc = acc\n",
    "#             torch.save(model.state_dict(), f'pretrained_models/model{m}.pt')\n",
    "\n",
    "        # pbar.set_postfix({'acc': corrects / counts, 'val acc': acc})\n",
    "    \n",
    "    torch.save(model.state_dict(), f'pretrained_models/model{m}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6abfc2f-6ade-4379-9952-c97f81c47ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
