{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "070c3c96-345d-45c5-a4e2-a61b0afddd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c835442-1084-4446-92cf-b93ea0aaf123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset = MNIST('./datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "valset = torch.utils.data.Subset(dataset, np.arange(10000))\n",
    "mnistloader = torch.utils.data.DataLoader(valset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93aea02-a7f0-4553-94d0-aa652323d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_cnn import MNIST_CNN\n",
    "\n",
    "model = MNIST_CNN().to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6a4f97-7dc5-4d4f-8b68-789a05aaf47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = os.listdir('datasets/PretrainedWeights/raw')\n",
    "num_models = len([w for w in weights if w.endswith('.pt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213d81a3-e417-441d-a55c-4ef800a8a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_val import mnist_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ae0a904-a7ad-4a1c-904c-52644f2a9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b3440d8-629d-4fea-bc06-738bc701cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [07:49<00:00,  1.07it/s, acc=0.947]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(range(num_models))\n",
    "for i in pbar:\n",
    "    weights = torch.load(f'datasets/PretrainedWeights/raw/model{i}.pt', map_location='cuda')\n",
    "    model.load_state_dict(weights)\n",
    "    model.eval()\n",
    "    acc = mnist_validation(mnistloader, model)\n",
    "    pbar.set_postfix({'acc': acc})\n",
    "    accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27a719-091c-4965-aef5-a7f60aa0ee7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e87133b-8957-4c4e-a66a-544e8058a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_list = [144, 16, 2304, 16, 25600, 64, 640, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50517be0-e758-479a-afa1-3bb30d0276b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dict2Vec(nn.Module):\n",
    "    def __init__(self, shape_list, hidden=256, reduce='add'):\n",
    "        assert reduce in ['add', 'cat']\n",
    "        self.reduce = reduce\n",
    "        super().__init__()\n",
    "        self.list = torch.nn.ModuleList([])\n",
    "        \n",
    "        for s in shape_list:\n",
    "            self.list.append(nn.Linear(s, hidden))\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden, hidden) if reduce == 'add' else nn.Linear(hidden * len(shape_list), hidden)\n",
    "        self.fc2 = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, weights):\n",
    "        x = 0. if self.reduce == 'add' else []\n",
    "        for i, v in enumerate(weights):\n",
    "            v = F.relu(self.list[i](v))\n",
    "            if self.reduce == 'cat':\n",
    "                x.append(v)\n",
    "            else:\n",
    "                x += v\n",
    "                \n",
    "        if self.reduce == 'add':\n",
    "            x /= len(weights)\n",
    "        else:\n",
    "            x = torch.cat(x, dim=-1)\n",
    "            \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8855f9-a84c-4d1b-ac11-240c1843d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = Dict2Vec(shape_list, 256).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d9fe0c-3a2d-4426-9f95-34fdd5f189ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c3d95c-e7b6-4886-85a4-6c9a31d85cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b480987d-deea-447d-af34-f994ff2f3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weight_datasets import PretrainedWeights, AdditiveNoise, SignFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a9cff2-23f2-4db0-8b65-535c6742ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = PretrainedWeights('datasets/PretrainedWeights/', transform=AdditiveNoise(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d814694a-597f-4532-ad81-bc98669533eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e92cd93-4d2f-4c3f-bf54-2e2386b1b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c1c92c-2f15-401f-8f15-56febf2d7b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ef4de-bd28-48a0-8517-4a3817dc349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation(dataloader, model):\n",
    "    corrects = 0\n",
    "    counts = 0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = [ins.to('cuda:0') for ins in inputs]\n",
    "        labels = labels.to('cuda:0')\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        preds = (outputs > 0.).detach().to(torch.float)\n",
    "        corrects += (preds == labels).sum()\n",
    "        counts += inputs[0].shape[0]\n",
    "    \n",
    "    return corrects / counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cdf75f-1416-4e00-9a1f-4e44991948b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(range(100))\n",
    "for epoch in pbar:  # loop over the dataset multiple times\n",
    "    losses = 0.\n",
    "    counts = 0\n",
    "    corrects = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = [ins.to('cuda:0') for ins in inputs]\n",
    "        labels = labels.to('cuda:0')\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = mlp(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses += loss.item() * inputs[0].shape[0]\n",
    "        counts += inputs[0].shape[0]\n",
    "        preds = (outputs > 0.).detach().to(torch.float)\n",
    "        corrects += (preds == labels).sum()\n",
    "\n",
    "    losses /= counts\n",
    "    train_acc = corrects / counts\n",
    "    \n",
    "    val_acc = validation(valloader, mlp)\n",
    "\n",
    "    pbar.set_postfix({'loss': losses, 'train_acc': train_acc, 'val_acc': val_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0bd643-060e-4f02-adf9-98a32aa47e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
