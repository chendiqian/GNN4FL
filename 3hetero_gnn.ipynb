{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b479c4f6-eb99-4c59-a079-4aef019f5d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3468e17b-0179-477a-b647-2bebc9ab48ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f14cdab-869e-4771-94e1-b1653650ac9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eff34bd-622a-4f94-9169-1020acb41722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_datasets import linear_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56362152-7c35-4676-b95c-ad4750104f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "for m_name in tqdm(os.listdir('/mnt/d/graph_dataset/raw')[10:]):\n",
    "    g = torch.load(f'/mnt/d/graph_dataset/raw/{m_name}')\n",
    "    model_dict = g.x_dict\n",
    "    aggr = model_dict['aggregator']\n",
    "    del model_dict['aggregator']\n",
    "    features = linear_mapping(model_dict, 1024)\n",
    "    \n",
    "    data = HeteroData(aggregator={'x': aggr},\n",
    "                      y=g.y)\n",
    "    data['clients'].x = features\n",
    "    \n",
    "    for k, w in g.edge_index_dict.items():\n",
    "        data[k].edge_index = w\n",
    "    \n",
    "    torch.save(data, f'/mnt/d/graph_dataset/raw/{m_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50e2cc-8f0b-4775-a5fa-6ee79644d957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70129e-ef05-4e30-bc39-6f704129b047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73dd8072-38c8-4f66-8014-526c130a5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_datasets import HeteroGraphDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbe0acb-50d4-41ae-8989-10fe4456d931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:10<00:00, 189.57it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = HeteroGraphDataset('/mnt/d/graph_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b371a47-a31e-43e6-be35-b31cc631dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from graph_utils import my_hetero_collate, separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f911b9-9c64-44c3-bd35-65adb3fc32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640458b6-149e-4346-a077-cd05606c8fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset[:1600], shuffle=True, batch_size=16, collate_fn=my_hetero_collate)\n",
    "val_loader = DataLoader(dataset[1600:1800], shuffle=False, batch_size=32, collate_fn=my_hetero_collate)\n",
    "test_loader = DataLoader(dataset[1800:2000], shuffle=False, batch_size=32, collate_fn=my_hetero_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f0970b-5deb-4b12-aea4-bbf731129151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc87f40-0d97-486d-8048-cdacb180518a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedd6968-f330-462f-ac1b-97c2e9ac0131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f50ec43-2355-4fb1-a64d-a444620b62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hetero_gnn import HeteroConv, HeteroGNN, HeteroGNNHomofeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b84b5760-f3fd-4c89-91d8-b77cff022068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = HeteroGNN(feature_in_channels=128,\n",
    "#                  aggr_in_channels=1,\n",
    "#                  hidden_channels=128,\n",
    "#                  out_channels=1,\n",
    "#                  num_layers=3,\n",
    "#                  feature_encode='mean').cuda()\n",
    "\n",
    "model = HeteroGNNHomofeatures(feature_in_channels=1024,\n",
    "                 aggr_in_channels=1,\n",
    "                 hidden_channels=128,\n",
    "                 out_channels=1,\n",
    "                 num_layers=3,).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7f145a5-ac07-4fc9-a41a-a189e9233608",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8528bf4-149b-4c44-a313-345a1dcc54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation(dataloader, model):\n",
    "    corrects = 0\n",
    "    counts = 0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        data = data.cuda()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(data.x_dict, data.edge_index_dict)\n",
    "        preds = (outputs > 0.).detach().to(torch.float)\n",
    "        corrects += (preds == data.y).sum()\n",
    "        counts += data.y.shape[0]\n",
    "    \n",
    "    return corrects / counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2da5a2e5-272e-4ece-8caf-5c70d497f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "958086e6-a89d-4442-b3e3-e02a8ce4a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b367d367-f8e0-4fa5-a3a1-37b3a18ad8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ce6c9a1-ad78-4e71-a333-1ddc2c72f4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it, loss=1.8e-5, train_acc=tensor(1., device='cuda:0'), val_acc=tensor(0.9989, device='cuda:0')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.9995999932289124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 15/15 [00:17<00:00,  1.16s/it, loss=1.62e-5, train_acc=tensor(1., device='cuda:0'), val_acc=tensor(0.9986, device='cuda:0')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.9990999698638916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 15/15 [00:16<00:00,  1.11s/it, loss=2.53e-5, train_acc=tensor(1., device='cuda:0'), val_acc=tensor(0.9989, device='cuda:0')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.9984999895095825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 15/15 [00:17<00:00,  1.17s/it, loss=1.69e-5, train_acc=tensor(1., device='cuda:0'), val_acc=tensor(0.9994, device='cuda:0')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.9994999766349792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 15/15 [00:17<00:00,  1.15s/it, loss=3.13e-5, train_acc=tensor(1., device='cuda:0'), val_acc=tensor(0.9991, device='cuda:0')]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.9993999600410461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(runs):\n",
    "    model.reset_parameters()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1.e-3)\n",
    "    pbar = tqdm(range(epochs))\n",
    "    for epoch in pbar:  # loop over the dataset multiple times\n",
    "        losses = 0.\n",
    "        counts = 0\n",
    "        corrects = 0\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            data = data.cuda()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(data.x_dict, data.edge_index_dict)\n",
    "            loss = criterion(outputs, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses += loss.item() * data.y.shape[0]\n",
    "            counts += data.y.shape[0]\n",
    "            preds = (outputs > 0.).detach().to(torch.float)\n",
    "            corrects += (preds == data.y).sum()\n",
    "\n",
    "        losses /= counts\n",
    "        train_acc = corrects / counts\n",
    "        \n",
    "        model.eval()\n",
    "        val_acc = validation(val_loader, model)\n",
    "\n",
    "        pbar.set_postfix({'loss': losses, 'train_acc': train_acc, 'val_acc': val_acc})\n",
    "    \n",
    "    model.eval()\n",
    "    test_acc = validation(test_loader, model)\n",
    "    print(f'test acc: {test_acc}')\n",
    "    test_accs.append(test_acc.cpu().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c3a1419-1672-43a1-977f-97f8ba93579d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992199778556824 ± 0.0003969860763201743\n"
     ]
    }
   ],
   "source": [
    "print(f'{np.mean(test_accs)} ± {np.std(test_accs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3accf-8240-41cb-98a7-273dd1610204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
